{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8f5cea6-73ac-45bc-a700-e5cbaf2126e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4002ddfc-238d-41b9-947c-cdb0505844cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scrapping(url, classname):\n",
    "    # Import Requests, Beautiful Soup\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    \"\"\"\n",
    "    :param url: URL for web scrapping\n",
    "    :param classname:  classname string of the element with reviews\n",
    "    :return: list \n",
    "\n",
    "    Request data for the url. \n",
    "    Create a soup (parse the html data).\n",
    "    Manually: go to inspect element on the reviews and check the class of the element.\n",
    "    Get and return the plain text (preferably in list format).\n",
    "    \"\"\"\n",
    "    print(f'Fetching data from {url} with class {classname}')\n",
    "    review_list = []\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        print('code 200, so far so good')\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        reviews = soup.findAll(class_=classname)\n",
    "\n",
    "        for review in reviews:\n",
    "            review_list.append(review.get_text())\n",
    "\n",
    "    print(f'Fetched data from {url}')\n",
    "    return review_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af51951c-acef-4976-b3e4-ad50ab9333c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(reviews):\n",
    "    # Import nltk - only use nltk library to perform all the following processing.\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "    \"\"\"\n",
    "    :param reviews: Reviews list\n",
    "    :return: Dataframe with processed reviews\n",
    "\n",
    "    Lower-case all words.\n",
    "    Remove all punctuations.\n",
    "    Remove stopwords. (Stopwords are the lists in the nltk library that are trivial and not relevant to the context/text.)\n",
    "    Perform lemmatization on the data.\n",
    "    \"\"\"\n",
    "    print('Initiating preprocessing')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    processed = pd.DataFrame()\n",
    "    processed['review'] = reviews['review'].str.lower()\n",
    "    processed['review'] = processed['review'].str.replace(f'[{string.punctuation}]','', regex=True)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def remove_stopwords(given_str):\n",
    "        words = given_str.split(' ')\n",
    "        new_str = []\n",
    "        for word in words:\n",
    "            if word not in stop_words and len(word) > 0:\n",
    "                new_str.append(word)\n",
    "        return ' '.join(new_str)\n",
    "    \n",
    "    processed['review'] = processed['review'].apply(remove_stopwords)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(given_str):\n",
    "        words = given_str.split(' ')\n",
    "        new_str = []\n",
    "        for word in words:\n",
    "            new_str.append(lemmatizer.lemmatize(word))\n",
    "        return ' '.join(new_str)\n",
    "\n",
    "    processed['review'] = processed['review'].apply(lemmatize)\n",
    "    reviews['cleaned_review'] = processed['review']\n",
    "\n",
    "    \n",
    "    print('Done preprocessing')\n",
    "    print(reviews)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e145cac-b734-43d0-8c4d-998b8a48121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://www.yelp.com/biz/the-peppersauce-cafe-phoenix with class comment__09f24__D0cxf css-qgunke\n",
      "code 200, so far so good\n",
      "Fetched data from https://www.yelp.com/biz/the-peppersauce-cafe-phoenix\n",
      "Fetching data from https://www.yelp.com/biz/wtf-burgers-phoenix?osq=Burgers with class comment__09f24__D0cxf css-qgunke\n",
      "code 200, so far so good\n",
      "Fetched data from https://www.yelp.com/biz/wtf-burgers-phoenix?osq=Burgers\n"
     ]
    }
   ],
   "source": [
    "# give your desired urls and classnames, preferably from yelp\n",
    "url1, url2 = \"https://www.yelp.com/biz/the-peppersauce-cafe-phoenix\", \"https://www.yelp.com/biz/wtf-burgers-phoenix?osq=Burgers\"\n",
    "classname1, classname2 = \"comment__09f24__D0cxf css-qgunke\", \"comment__09f24__D0cxf css-qgunke\"\n",
    "\n",
    "# Part 1\n",
    "review_list1 = web_scrapping(url1, classname1)\n",
    "review_list2 = web_scrapping(url2, classname2)\n",
    "\n",
    "# Create a pandas dataframe from array\n",
    "df1 = pd.DataFrame(np.array(review_list1), columns=['review'])\n",
    "df2 = pd.DataFrame(np.array(review_list2), columns=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11473ca9-f5b1-41f4-abdc-17f144a06d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating preprocessing\n",
      "Done preprocessing\n",
      "                                              review  \\\n",
      "0  Ask for Janette and enjoy whatever she recco's...   \n",
      "1  Found this place because I was looking for som...   \n",
      "2  If you're looking for some serious home cookin...   \n",
      "3  This place was super good and filling! We came...   \n",
      "4  Good food, clean and great vibe!  Little off b...   \n",
      "5  Delicious breakfast! Simple done well. Has bro...   \n",
      "6  Came here today with my mom to have lunch. Wai...   \n",
      "7  Okay, I'm impressed! It's very nondescript fro...   \n",
      "8  Everything I ordered was exactly the way I mos...   \n",
      "9  Classic southern style dinerService is quick &...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  ask janette enjoy whatever recco ive 3 time so...  \n",
      "1  found place looking someplace quick reputable ...  \n",
      "2  youre looking serious home cooking place  noth...  \n",
      "3  place super good filling came tuesday around 1...  \n",
      "4  good food clean great vibe  little beaten path...  \n",
      "5  delicious breakfast simple done well brow cris...  \n",
      "6  came today mom lunch waitress friendly spoke s...  \n",
      "7  okay im impressed nondescript outside wouldnt ...  \n",
      "8  everything ordered exactly way prefer got corn...  \n",
      "9  classic southern style dinerservice quick want...  \n",
      "Initiating preprocessing\n",
      "Done preprocessing\n",
      "                                              review  \\\n",
      "0  This is my 3rd time back, since I happened to ...   \n",
      "1  I ordered a grilled chicken  sandwich and the ...   \n",
      "2  OK. This is one of those \"we make everything\" ...   \n",
      "3  Great food and prices. Traveled from Michigan ...   \n",
      "4  Stopped here for a casual business meeting and...   \n",
      "5  Love this place! So much variety to meet every...   \n",
      "6  If I could give this place a zero star rating ...   \n",
      "7  The portions are great, they had so many choic...   \n",
      "8  My sister and I visited this establishment fro...   \n",
      "9  This is a great place for feeding your burger ...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  3rd time back since happened areai went heart ...  \n",
      "1  ordered grilled chicken  sandwich sweet potato...  \n",
      "2  ok one make everything place delicious health ...  \n",
      "3  great food price traveled michigan ate definit...  \n",
      "4  stopped casual business meeting pleasantly sur...  \n",
      "5  love place much variety meet everyones desire ...  \n",
      "6  could give place zero star rating would ive ea...  \n",
      "7  portion great many choice personally loved bur...  \n",
      "8  sister visited establishment yelp search come ...  \n",
      "9  great place feeding burger craving staff aweso...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rhishabhhattarki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhishabhhattarki/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rhishabhhattarki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhishabhhattarki/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Part 2\n",
    "processed_review1 = preprocessing(df1)\n",
    "processed_review2 = preprocessing(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91668ad-4cf4-4b4e-9d62-06d513438927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
